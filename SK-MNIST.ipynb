{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXynxrMQYZ30"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5435,
     "status": "ok",
     "timestamp": 1742156453432,
     "user": {
      "displayName": "Dimitri Caputo",
      "userId": "12075933984764029925"
     },
     "user_tz": -60
    },
    "id": "DOD-qHOuYZ33"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Rescaling, Dropout, Resizing\n",
    "from keras.layers import RandomFlip, RandomTranslation, RandomRotation, RandomZoom, MultiHeadAttention, AugMix, RandAugment\n",
    "from keras.models import Sequential\n",
    "from keras.metrics import F1Score, Precision, AUC\n",
    "from keras.losses import CategoricalFocalCrossentropy, BinaryFocalCrossentropy\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers.schedules import ExponentialDecay, CosineDecay\n",
    "from keras.optimizers import AdamW\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, KMeansSMOTE\n",
    "from imblearn.under_sampling import TomekLinks, RepeatedEditedNearestNeighbours\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxVKOcXMYZ38"
   },
   "source": [
    "# Move images into class folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJQRTSqjYZ4a"
   },
   "outputs": [],
   "source": [
    "def move_and_separate_images(list_of_folders, df_metadata):\n",
    "    df_metadata = df_metadata.set_index('image_id', drop=True)\n",
    "    count = 0\n",
    "    for folder in list_of_folders:\n",
    "        for root, dirs, files in os.walk(folder):\n",
    "            for file in files:\n",
    "                try:\n",
    "                    os.makedirs(f\"dataset/{df_metadata.loc[file.strip('.jpg'), 'dx']}\")\n",
    "                except:\n",
    "                    source=os.path.join(root, file)\n",
    "                    destination=os.path.join('dataset', df_metadata.loc[file.strip('.jpg'), 'dx'], file)\n",
    "                    os.rename(source,destination)\n",
    "                    count += 1\n",
    "                    if count%100 == 0:\n",
    "                        print(f'{count} images were processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMuxfLJ-YZ4b"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('HAM10000_metadata.csv')\n",
    "\n",
    "move_and_separate_images(['HAM10000_images_part_1', 'HAM10000_images_part_2'], df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move images into cancerous/non cancerous folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    \"akiec\": \"canc\",\n",
    "    \"bcc\": \"canc\",\n",
    "    \"bkl\": \"nocanc\",\n",
    "    \"df\": \"nocanc\",\n",
    "    \"mel\": \"canc\",\n",
    "    \"nv\": \"nocanc\",\n",
    "    \"vasc\": \"nocanc\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_and_separate_images(list_of_folders, df_metadata):\n",
    "    df_metadata = df_metadata.set_index('image_id', drop=True)\n",
    "    count = 0\n",
    "    for folder in list_of_folders:\n",
    "        for root, dirs, files in os.walk(folder):\n",
    "            for file in files:\n",
    "                try:\n",
    "                    os.makedirs(f\"dataset/{class_mapping[df_metadata.loc[file.strip('.jpg'), 'dx']]}\")\n",
    "                except:\n",
    "                    source=os.path.join(root, file)\n",
    "                    destination=os.path.join('dataset', class_mapping[df_metadata.loc[file.strip('.jpg'), 'dx']], file)\n",
    "                    os.rename(source,destination)\n",
    "                    count += 1\n",
    "                    if count%100 == 0:\n",
    "                        print(f'{count} images were processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('HAM10000_metadata.csv')\n",
    "\n",
    "move_and_separate_images(['HAM10000_images_part_1', 'HAM10000_images_part_2'], df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMe2KXHYYZ3-"
   },
   "outputs": [],
   "source": [
    "def array_from_images(folder, df_metadata, dict_of_labels, h=224, w=224, channels=3):\n",
    "    # Create an array of images and labels the size of the number of pictures\n",
    "    nb_files = 0\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            nb_files += 1\n",
    "    array = np.zeros(shape=(nb_files, h, w, channels))\n",
    "    labels = np.zeros(shape=(nb_files,))\n",
    "\n",
    "    # Check the name and fill array and labels\n",
    "    df_metadata = df_metadata.set_index('image_id', drop=True)\n",
    "    count = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            with Image.open(os.path.join(root, file)) as im:\n",
    "                array[count,:,:,:] = np.asarray(im.resize((h,w)))\n",
    "                try:\n",
    "                    labels[count] = dict_of_labels[class_mapping[df_metadata.loc[file.strip('.jpg'), 'dx']]]\n",
    "                except:\n",
    "                    labels[count] = dict_of_labels[df_metadata.loc[file.strip('.jpg'), 'dx']]\n",
    "                count += 1\n",
    "                if count%100 == 0:\n",
    "                    print(f'{count} images were processed')\n",
    "    return array, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    \"akiec\": \"canc\",\n",
    "    \"bcc\": \"canc\",\n",
    "    \"bkl\": \"nocanc\",\n",
    "    \"df\": \"nocanc\",\n",
    "    \"mel\": \"canc\",\n",
    "    \"nv\": \"nocanc\",\n",
    "    \"vasc\": \"nocanc\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "wXfmnnH1YZ3_",
    "outputId": "caf9c7d6-299d-4569-cbc9-647f005a16d8"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('HAM10000_metadata.csv')\n",
    "# dict_label = {k:v for k,v in zip(['nocanc', 'canc'], range(2))}\n",
    "dict_label = {k:v for k,v in zip(list(class_mapping.keys()), range(7))}\n",
    "size = 224\n",
    "\n",
    "X, y = array_from_images('dataset/', df, dict_label, h=size, w=size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(f'X-{size}x{size}', X, allow_pickle=True)\n",
    "np.savez_compressed(f'y-{size}x{size}', y, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1742156799969,
     "user": {
      "displayName": "Dimitri Caputo",
      "userId": "12075933984764029925"
     },
     "user_tz": -60
    },
    "id": "XPerG9OeY6Bm"
   },
   "outputs": [],
   "source": [
    "size = 224\n",
    "X = np.load(f'X-{size}x{size}.npz')['arr_0']\n",
    "y = np.load(f'y-{size}x{size}.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {i:(len(y)/(7 * sum(y==i))).item() for i in range(7)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.array(range(7)), y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1044,
     "status": "ok",
     "timestamp": 1742156874055,
     "user": {
      "displayName": "Dimitri Caputo",
      "userId": "12075933984764029925"
     },
     "user_tz": -60
    },
    "id": "YQWIcLFUYZ4B"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X, y_train, y = train_test_split(X, y, stratify=y, test_size=0.2, random_state=38)\n",
    "\n",
    "\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X, y, stratify=y, test_size=0.5, random_state=38)\n",
    "\n",
    "del X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wy2K0zqVYZ4N"
   },
   "source": [
    "# SMOTETOMEK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 855220,
     "status": "ok",
     "timestamp": 1741377156881,
     "user": {
      "displayName": "Dimitri Caputo",
      "userId": "12075933984764029925"
     },
     "user_tz": -60
    },
    "id": "I5f-Z8aOYZ4O",
    "outputId": "aa74acca-cf2d-4743-b399-9142749c28df"
   },
   "outputs": [],
   "source": [
    "shape_origin = X_train.shape\n",
    "\n",
    "X_train = np.reshape(X_train, (shape_origin[0], shape_origin[1]*shape_origin[2]*shape_origin[3]))\n",
    "\n",
    "smotetomek = SMOTETomek(random_state=38, n_jobs=-1)\n",
    "\n",
    "X_train, y_train = smotetomek.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], shape_origin[1], shape_origin[2], shape_origin[3]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eugcgC1Ihbe7"
   },
   "source": [
    "# One Hot Encoding of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1742156903324,
     "user": {
      "displayName": "Dimitri Caputo",
      "userId": "12075933984764029925"
     },
     "user_tz": -60
    },
    "id": "GZnGDhBaYZ4V"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hofZJHSSYZ4d"
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1742156960318,
     "user": {
      "displayName": "Dimitri Caputo",
      "userId": "12075933984764029925"
     },
     "user_tz": -60
    },
    "id": "9ZlCHMEhYZ4e"
   },
   "outputs": [],
   "source": [
    "def get_earlystopping(patience=10):\n",
    "    early_stopping = EarlyStopping(\n",
    "    monitor='val_mean_average_precision',\n",
    "    mode='max',\n",
    "    patience=patience,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True)\n",
    "    return early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742156960330,
     "user": {
      "displayName": "Dimitri Caputo",
      "userId": "12075933984764029925"
     },
     "user_tz": -60
    },
    "id": "-cFyIbR9YZ4f"
   },
   "outputs": [],
   "source": [
    "def plot_learning_curves(model):\n",
    "    fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "    ax[0].plot(model.history.history['val_f1_score'], label='val_f1_score')\n",
    "    ax[0].plot(model.history.history['f1_score'], label='f1_score')\n",
    "    ax[0].legend()\n",
    "    try:\n",
    "        ax[1].plot(model.history.history['val_average_precision'], label='val_avg_prec')\n",
    "        ax[1].plot(model.history.history['average_precision'], label='avg_prec')\n",
    "        ax[1].legend()\n",
    "    except:\n",
    "        pass\n",
    "    #     ax[1].plot(model.history.history['val_precision_1'], label='val_precision_1')\n",
    "    #     ax[1].plot(model.history.history['precision_1'], label='precision_1')\n",
    "    #     ax[1].legend()\n",
    "    ax[2].plot(model.history.history['val_loss'], label='val_loss')\n",
    "    ax[2].plot(model.history.history['loss'], label='loss')\n",
    "    ax[2].legend()\n",
    "    fig.show;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1742156960338,
     "user": {
      "displayName": "Dimitri Caputo",
      "userId": "12075933984764029925"
     },
     "user_tz": -60
    },
    "id": "9CmLrebcYZ4f"
   },
   "outputs": [],
   "source": [
    "def get_analysis(model, testX, testy):\n",
    "    plot_learning_curves(model)\n",
    "    loss, f1, avg_prec = model.evaluate(testX, testy)\n",
    "    print(f'The model gave')\n",
    "    print(f'Loss: {loss:.2f}')\n",
    "    print(f'F1 Macro: {f1:.2f}')\n",
    "    print(f'Avg Prec: {avg_prec:.2f}')\n",
    "    y_pred = model.predict(testX)\n",
    "    y_res = np.argmax(y_pred, axis=1)\n",
    "    print(classification_report(testy, y_res))\n",
    "    return y_pred, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1742156960342,
     "user": {
      "displayName": "Dimitri Caputo",
      "userId": "12075933984764029925"
     },
     "user_tz": -60
    },
    "id": "vSwR8z6vYZ4g"
   },
   "outputs": [],
   "source": [
    "def get_analysis_cat(model, testX, testy):\n",
    "    plot_learning_curves(model)\n",
    "    loss, f1, avg_prec = model.evaluate(testX, testy)\n",
    "    print(f'The model gave')\n",
    "    print(f'Loss: {loss:.2f}')\n",
    "    print(f'F1 Macro: {f1:.2f}')\n",
    "    print(f'Avg Prec: {avg_prec:.2f}')\n",
    "    predy = model.predict(testX)\n",
    "    resy = to_categorical(np.argmax(predy, axis=1))\n",
    "    print(classification_report(testy,resy))\n",
    "    return predy, resy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1742156960431,
     "user": {
      "displayName": "Dimitri Caputo",
      "userId": "12075933984764029925"
     },
     "user_tz": -60
    },
    "id": "B6g22E4HYZ4h"
   },
   "outputs": [],
   "source": [
    "def compile_and_train(model, loss, opt, metrics, epochs, patience=None, steps=None, class_weight=None):\n",
    "    model.compile(loss=loss,\n",
    "                optimizer=opt,\n",
    "                metrics=metrics)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    if patience != None:\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=epochs,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[get_earlystopping(patience)],\n",
    "            steps_per_epoch=steps,\n",
    "            class_weight=class_weight\n",
    "            )\n",
    "    else:\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=epochs,\n",
    "            validation_data=(X_val, y_val),\n",
    "            steps_per_epoch=steps,\n",
    "            class_weight=class_weight\n",
    "            )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-89oUqvkJKb"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import EfficientNetV2B0, EfficientNetV2S\n",
    "\n",
    "effnet = EfficientNetV2B0(\n",
    "    include_top=True,\n",
    "    input_shape=X_train.shape[1:],\n",
    "    weights=None,\n",
    "    classes=7,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1:])),\n",
    "    Rescaling(scale=1./255),\n",
    "    RandAugment(value_range=(0,1), num_ops=1, factor=0.1),\n",
    "    effnet, \n",
    "    # Dropout(0.2),\n",
    "    # Flatten(),\n",
    "    # Dense(16, activation='relu'),\n",
    "    # Dense(7, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(y_true, y_pred):\n",
    "    aps = []\n",
    "    for c in range(7):\n",
    "        ap = average_precision_score(y_true.detach().cpu().numpy()[:, c], y_pred.detach().cpu().numpy()[:, c])\n",
    "        aps.append(ap)\n",
    "\n",
    "    mAP = sum(aps) / len(aps)\n",
    "    return mAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rand_augment_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandAugment</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetv2-b0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,928,279</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling_3 (\u001b[38;5;33mRescaling\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rand_augment_1 (\u001b[38;5;33mRandAugment\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetv2-b0 (\u001b[38;5;33mFunctional\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │     \u001b[38;5;34m5,928,279\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,928,279</span> (22.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,928,279\u001b[0m (22.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,867,671</span> (22.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,867,671\u001b[0m (22.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,608</span> (236.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m60,608\u001b[0m (236.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m 24/251\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:04\u001b[0m 1s/step - f1_score: 0.1254 - loss: 0.5339 - mean_average_precision: 0.1910"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m lr_schedule = CosineDecay(initial_learning_rate=\u001b[32m1e-3\u001b[39m, decay_steps=\u001b[32m500\u001b[39m, alpha=\u001b[32m0.01\u001b[39m) \n\u001b[32m      2\u001b[39m optimizer = AdamW(learning_rate=lr_schedule, weight_decay=\u001b[32m0.01\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m history020 = \u001b[43mcompile_and_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                               \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCategoricalFocalCrossentropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                               \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                               \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmean_average_precision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF1Score\u001b[49m\u001b[43m(\u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmacro\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m                               \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                               \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m                            \u001b[49m\u001b[38;5;66;43;03m#    class_weight=class_weights\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mcompile_and_train\u001b[39m\u001b[34m(model, loss, opt, metrics, epochs, patience, steps, class_weight)\u001b[39m\n\u001b[32m      6\u001b[39m model.summary()\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m patience != \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mget_earlystopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weight\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     19\u001b[39m     model.fit(\n\u001b[32m     20\u001b[39m         X_train,\n\u001b[32m     21\u001b[39m         y_train,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m         class_weight=class_weight\n\u001b[32m     26\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SK-MNIST/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SK-MNIST/.venv/lib/python3.11/site-packages/keras/src/backend/torch/trainer.py:269\u001b[39m, in \u001b[36mTorchTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, data \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    266\u001b[39m     \u001b[38;5;66;03m# Callbacks\u001b[39;00m\n\u001b[32m    267\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m     \u001b[38;5;66;03m# Callbacks\u001b[39;00m\n\u001b[32m    272\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SK-MNIST/.venv/lib/python3.11/site-packages/keras/src/backend/torch/trainer.py:124\u001b[39m, in \u001b[36mTorchTrainer.make_train_function.<locals>.one_step_on_data\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[32m    123\u001b[39m data = data[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SK-MNIST/.venv/lib/python3.11/site-packages/keras/src/backend/torch/trainer.py:69\u001b[39m, in \u001b[36mTorchTrainer.train_step\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Compute gradients\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trainable_weights:\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# Call torch.Tensor.backward() on the loss to compute gradients\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# for the weights.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m     trainable_weights = \u001b[38;5;28mself\u001b[39m.trainable_weights[:]\n\u001b[32m     72\u001b[39m     gradients = [v.value.grad \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m trainable_weights]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SK-MNIST/.venv/lib/python3.11/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SK-MNIST/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/SK-MNIST/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "lr_schedule = CosineDecay(initial_learning_rate=1e-3, decay_steps=500, alpha=0.01) \n",
    "optimizer = AdamW(learning_rate=lr_schedule, weight_decay=0.01)\n",
    "\n",
    "\n",
    "history020 = compile_and_train(model,\n",
    "                               loss=CategoricalFocalCrossentropy(),\n",
    "                               opt=optimizer,\n",
    "                               metrics=[mean_average_precision, F1Score(average='macro')],\n",
    "                               epochs=500,\n",
    "                               patience=50, \n",
    "                            #    class_weight=class_weights\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2523,
     "status": "ok",
     "timestamp": 1741549218014,
     "user": {
      "displayName": "Dimitri Caputo",
      "userId": "12075933984764029925"
     },
     "user_tz": -60
    },
    "id": "hec7w51oqirk",
    "outputId": "7192e3b4-9b61-4c26-a7d7-b6bcd955eff7"
   },
   "outputs": [],
   "source": [
    "pred, res = get_analysis_cat(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model_avgprec_90_f1_69_env2b0_128px.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(list(class_weights.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "sk-mnist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
